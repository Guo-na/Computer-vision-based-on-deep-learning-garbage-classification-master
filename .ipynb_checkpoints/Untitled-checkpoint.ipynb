{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, cv2, random,time\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Flatten,MaxPooling2D,Dense \n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(data_path):\n",
    "    \"\"\"\n",
    "    数据处理\n",
    "    :param data_path: 数据集路径\n",
    "    :return: train, test:处理后的训练集数据、测试集数据\n",
    "    \"\"\"\n",
    "    train_data = ImageDataGenerator(\n",
    "            # 对图片的每个像素值均乘上这个放缩因子，把像素值放缩到0和1之间有利于模型的收敛\n",
    "            rescale=1. / 225,  \n",
    "            # 浮点数，剪切强度（逆时针方向的剪切变换角度）\n",
    "            shear_range=0.1,  \n",
    "            # 随机缩放的幅度，若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]\n",
    "            zoom_range=0.1,\n",
    "            # 浮点数，图片宽度的某个比例，数据提升时图片水平偏移的幅度\n",
    "            width_shift_range=0.1,\n",
    "            # 浮点数，图片高度的某个比例，数据提升时图片竖直偏移的幅度\n",
    "            height_shift_range=0.1,\n",
    "            # 布尔值，进行随机水平翻转\n",
    "            horizontal_flip=True,\n",
    "            # 布尔值，进行随机竖直翻转\n",
    "            vertical_flip=True,\n",
    "            # 在 0 和 1 之间浮动。用作验证集的训练数据的比例\n",
    "            validation_split=0.1  \n",
    "    )\n",
    "\n",
    "    # 接下来生成测试集，可以参考训练集的写法\n",
    "    validation_data = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            validation_split=0.1)\n",
    "\n",
    "    train_generator = train_data.flow_from_directory(\n",
    "            # 提供的路径下面需要有子目录\n",
    "            data_path, \n",
    "            # 整数元组 (height, width)，默认：(256, 256)。 所有的图像将被调整到的尺寸。\n",
    "            target_size=(150, 150),\n",
    "            # 一批数据的大小\n",
    "            batch_size=16,\n",
    "            # \"categorical\", \"binary\", \"sparse\", \"input\" 或 None 之一。\n",
    "            # 默认：\"categorical\",返回one-hot 编码标签。\n",
    "            class_mode='categorical',\n",
    "            # 数据子集 (\"training\" 或 \"validation\")\n",
    "            subset='training', \n",
    "            seed=0)\n",
    "    validation_generator = validation_data.flow_from_directory(\n",
    "            data_path,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=16,\n",
    "            class_mode='categorical',\n",
    "            subset='validation',\n",
    "            seed=0)\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_generator, validation_generator, save_model_path):\n",
    "    \"\"\"\n",
    "    模型的建立\n",
    "    本次实验采用Vgg16模型\n",
    "    \"\"\"\n",
    "    vgg16_model = VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=vgg16_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(vgg16_model)\n",
    "    model.add(top_model)\n",
    "    # 编译模型, 采用 compile 函数: https://keras.io/models/model/#compile\n",
    "    model.compile(\n",
    "             # 是优化器, 主要有Adam、sgd、rmsprop等方式。\n",
    "            optimizer=SGD(lr=1e-3,momentum=0.9),\n",
    "            # 损失函数,多分类采用 categorical_crossentropy\n",
    "            loss='categorical_crossentropy',\n",
    "            # 是除了损失函数值之外的特定指标, 分类问题一般都是准确率\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    model.fit_generator(\n",
    "            # 一个生成器或 Sequence 对象的实例\n",
    "            generator=train_generator,\n",
    "            # epochs: 整数，数据的迭代总轮数。\n",
    "            epochs=5,\n",
    "            # 一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "            steps_per_epoch=2259 // 16,\n",
    "            # 验证集\n",
    "            validation_data=validation_generator,\n",
    "             # 在验证集上,一个epoch包含的步数,通常应该等于你的数据集的样本数量除以批量大小。\n",
    "            validation_steps=248 // 16,\n",
    "            )\n",
    "    model.save(save_model_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mode(validation_generator, save_model_path):\n",
    "     # 加载模型\n",
    "    model = load_model('results/Ynnex1.h5')\n",
    "    # 获取验证集的 loss 和 accuracy\n",
    "    loss, accuracy = model.evaluate_generator(validation_generator)\n",
    "    print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    主要步骤:\n",
    "        1.加载模型(请加载你认为的最佳模型)\n",
    "        2.图片处理\n",
    "        3.用加载的模型预测图片的类别\n",
    "    :param img: PIL.Image 对象\n",
    "    :return: string, 模型识别图片的类别, \n",
    "            共 'cardboard','glass','metal','paper','plastic','trash' 6 个类别\n",
    "    \"\"\"\n",
    "    # 把图片转换成为numpy数组\n",
    "    img = img.resize((150, 150))\n",
    "    img = image.img_to_array(img)\n",
    "    \n",
    "    # 加载模型,加载请注意 model_path 是相对路径, 与当前文件同级。\n",
    "    # 如果你的模型是在 results 文件夹下的 dnn.h5 模型，则 model_path = 'results/dnn.h5'\n",
    "    model_path = 'results/Ynnex1.h5'\n",
    "    try:\n",
    "        # 作业提交时测试用, 请勿删除此部分\n",
    "        model_path = os.path.realpath(__file__).replace('main.py', model_path)\n",
    "    except NameError:\n",
    "        model_path = './' + model_path\n",
    "    \n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    # 加载模型\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # expand_dims的作用是把img.shape转换成(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # 模型预测\n",
    "    y = model.predict(x)\n",
    "\n",
    "    # 获取labels\n",
    "    labels = {0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    predict = labels[np.argmax(y)]\n",
    "\n",
    "    # 返回图片的类别\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    深度学习模型训练流程,包含数据处理、创建模型、训练模型、模型保存、评价模型等。\n",
    "    如果对训练出来的模型不满意,你可以通过调整模型的参数等方法重新训练模型,直至训练出你满意的模型。\n",
    "    如果你对自己训练出来的模型非常满意,则可以提交作业!\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_path = \"./dataset-resized\"  # 数据集路径\n",
    "    save_model_path = 'results/Ynnex1.h5'  # 保存模型路径和名称\n",
    "    # 获取数据\n",
    "    train_generator, validation_generator = processing_data(data_path)\n",
    "    # 创建、训练和保存模型\n",
    "    model(train_generator, validation_generator, save_model_path)\n",
    "    # 评估模型\n",
    "    evaluate_mode(validation_generator, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2269 images belonging to 6 classes.\n",
      "Found 250 images belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\APP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 91/141 [==================>...........] - ETA: 7:42 - loss: 1.8825 - accuracy: 0.2655"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
